{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = r'C:\\Users\\anany\\AppData\\Local\\Continuum\\anaconda3\\pkgs\\proj4-5.2.0-ha925a31_1\\Library\\share'\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import re\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Fire_Data.csv\")\n",
    "df = df.dropna()\n",
    "df = df[['Date', 'Geolocation']]\n",
    "def getLocation(val):\n",
    "    l = re.findall('\\[.*\\]', val)[0]\n",
    "    l = l.lstrip('[').rstrip(']')\n",
    "    l = l.split(',')\n",
    "    return [float(l[0]), float(l[1])]\n",
    "def getX(val):\n",
    "    return val[0]\n",
    "def getY(val):\n",
    "    return val[1]\n",
    "df['loc'] = df['Geolocation'].apply(getLocation)\n",
    "df['x'] = df['loc'].apply(getX)\n",
    "df['y'] = df['loc'].apply(getY)\n",
    "df = df[['Date', 'x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Fire_Data.csv\")\n",
    "df = df.dropna()\n",
    "df = df[['Date', 'Geolocation']]\n",
    "def getLocation(val):\n",
    "    l = re.findall('\\[.*\\]', val)[0]\n",
    "    l = l.lstrip('[').rstrip(']')\n",
    "    l = l.split(',')\n",
    "    return [float(l[0]), float(l[1])]\n",
    "def getX(val):\n",
    "    return val[0]\n",
    "def getY(val):\n",
    "    return val[1]\n",
    "df['loc'] = df['Geolocation'].apply(getLocation)\n",
    "df['x'] = df['loc'].apply(getX)\n",
    "df['y'] = df['loc'].apply(getY)\n",
    "df = df[['Date', 'x', 'y']]\n",
    "##################################################################################\n",
    "df = df.sort_values(by = 'Date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "\n",
    "y = df['x'].resample('12H').mean().to_frame().reset_index()\n",
    "y['ffilData'] = y['x'].fillna(method='ffill')\n",
    "y['backfillData'] = y['x'].fillna(method='bfill')\n",
    "y['x'] = (y['ffilData'] + y['backfillData'])/2\n",
    "\n",
    "y = y[['Date', 'x']]\n",
    "y = y.set_index('Date')\n",
    "\n",
    "result_mul = seasonal_decompose(y['x'], model='additive', extrapolate_trend='freq', freq = 3)\n",
    "listOfArima = []\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(y, order=param, \n",
    "                                            seasonal_order=param_seasonal, \n",
    "                                            enforce_stationarity=False, \n",
    "                                            enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            listOfArima.append([param, param_seasonal, results.aic])\n",
    "        except:\n",
    "            continue\n",
    "min = 1000\n",
    "j = 0\n",
    "for i in listOfArima:\n",
    "    if i[2] < min:\n",
    "        j = i\n",
    "        min = i[2]\n",
    "mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                order=j[0],\n",
    "                                seasonal_order=j[1],\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "j = results.forecast(steps = 4).to_frame()\n",
    "j_x = j.rename(columns = {0:'x'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y'].resample('12H').mean().to_frame().reset_index()\n",
    "y['ffilData'] = y['y'].fillna(method='ffill')\n",
    "y['backfillData'] = y['y'].fillna(method='bfill')\n",
    "y['y'] = (y['ffilData'] + y['backfillData'])/2\n",
    "y = y[['Date', 'y']]\n",
    "y = y.set_index('Date')\n",
    "\n",
    "result_mul = seasonal_decompose(y['y'], model='additive', extrapolate_trend='freq', freq = 3)\n",
    "listOfArima = []\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(y, order=param, \n",
    "                                            seasonal_order=param_seasonal, \n",
    "                                            enforce_stationarity=False, \n",
    "                                            enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            listOfArima.append([param, param_seasonal, results.aic])\n",
    "        except:\n",
    "            continue\n",
    "min = 1000\n",
    "j = 0\n",
    "for i in listOfArima:\n",
    "    if i[2] < min:\n",
    "        j = i\n",
    "        min = i[2]\n",
    "mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                order=j[0],\n",
    "                                seasonal_order=j[1],\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results_y = mod.fit()\n",
    "\n",
    "j = results.forecast(steps = 4).to_frame()\n",
    "j_y = j.rename(columns = {0:'y'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['34.36930492706232', '-119.10185276526958', 1], ['34.368365960097414', '-119.135715155373', 2], ['34.36631810673867', '-119.16958717304676', 3], ['34.36915429839143', '-119.2034688210281', 4]]\n"
     ]
    }
   ],
   "source": [
    "J_x_1 = j_x.reset_index()\n",
    "J_x_1 = J_x_1.rename(columns = {'index':'Date'})\n",
    "\n",
    "J_y_1 = j_y.reset_index()\n",
    "J_y_1 = J_y_1.rename(columns = {'index':'Date'})\n",
    "\n",
    "dfnew = J_x_1.merge(J_y_1, left_on = 'Date', right_on = 'Date')\n",
    "dfnew['Date'] = dfnew.index + 1\n",
    "\n",
    "def toStringData(val):\n",
    "    return str(val)\n",
    "\n",
    "dfnew['x'] = dfnew['x'].map(toStringData)\n",
    "dfnew['y'] = dfnew['y'].map(toStringData)\n",
    "dfnew = dfnew[['y', 'x', 'Date']]\n",
    "dfnew = dfnew.values.tolist()\n",
    "print(dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_uc = results.get_forecast(steps=12)\n",
    "# pred_ci = pred_uc.conf_int()\n",
    "\n",
    "# ax = y.plot(label='observed', figsize=(14, 7))\n",
    "# pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "# ax.fill_between(pred_ci.index,\n",
    "#                 pred_ci.iloc[:, 0],\n",
    "#                 pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "# ax.set_xlabel('Date')\n",
    "# ax.set_ylabel('Furniture Sales')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# meanX = df['x'].mean()\n",
    "# meanY = df['y'].mean()\n",
    "# print(meanX)\n",
    "# print(meanY)\n",
    "# m = Basemap(projection='lcc', resolution='h',\n",
    "#             width=1E5, height=1.2E5,\n",
    "#             llcrnrlon = meanX - 1,\n",
    "#             llcrnrlat = meanY - 1, \n",
    "#             urcrnrlon = meanX + 1, \n",
    "#             urcrnrlat = meanY + 1,\n",
    "#            lat_0=meanY, lon_0=meanX, epsg = 4326)\n",
    "# m.etopo()\n",
    "# type_of_service = 'NatGeo_World_Map'\n",
    "# m.arcgisimage(service = type_of_service, xpixels = 2000)\n",
    "\n",
    "# for i in range(len(df)):\n",
    "#     x, y = m(df.iloc[i, 1], df.iloc[i, 2])\n",
    "#     plt.plot(x, y, 'ok', markersize=5)\n",
    "#     plt.text(x, y, df.iloc[i, 0], fontsize=12);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_output_new.csv\")\n",
    "print(df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
